Assignment Overview:
In this project, a single-threaded server was created that acts like a key-value store. This server can store data with unique keys, similar to a simple database. 
Clients can interact with the server using two common network protocols, TCP and UDP. This implementation involves basic operations like adding (PUT), retrieving (GET), and deleting (DELETE) key-value pairs. 
The project emphasized robust design for clear data exchange, error handling mechanisms like timeouts for delayed messages, and the ability to identify corrupted data packets. 
Additionally, logging communication activities was crucial for monitoring server behavior and troubleshooting issues. 
Overall, this project is aimed to solidify understanding of network communication, socket programming, and error handling in distributed systems.



Technical Impression:
Building this project provided valuable insights into network programming and how protocols function. 
I gained practical experience with TCP and UDP communication, understanding their strengths and weaknesses in reliability and speed. 
Furthermore, by incorporating timeouts and malformed packet detection, I learned how error handling is crucial for maintaining a stable and robust system in a network environment. 
In this project I also used Docker, a tool used to containerize applications. 
This exposure helped me to the revisit concepts of containerization and micro-services, which are fundamental building blocks for modern distributed systems.
To ensure malformed packet detection in UDP (where it in not an out-of-box feature) I designed a checksum strategy which helped me learn more about packet loss and its detection in not so reliable conditions.

Use Case:
This key-value store has practical applications in distributed web environments like a web application running on multiple servers. 
These servers often need to share data, such as configuration settings or user session information. Your key-value store can act as a central hub for this shared data. 
Each server can efficiently access and modify the data stored with unique keys. 
This promotes consistency (all servers have the same data) and scalability (you can easily add more servers without worrying about data duplication).

